# Benchmarks vs. System Metrics: When and Why to Use Them

Optimize your simulation performance and costs using two complementary data sources: benchmarks for upfront machine selection and system metrics for post-simulation analysis and refinement.

[Benchmarks](https://inductiva.ai/guides/scale-up/benchmark/index) help you choose the right machine before you run a full simulation. They’re a quick test that shows how your code performs across different machine types — so you can pick the best fit for speed and cost efficiency without wasting credits on trial and error. Always run a benchmark when you’re setting up a new project, trying new software, or testing different workloads.  

[System Metrics](system-metrics.md) help you understand how your chosen machine was actually used after the task completes. By looking at CPU, memory, and disk stats, you can check if you over- or under-provisioned resources. This helps you tweak future runs — maybe you can save money with a smaller machine, or speed things up with more cores or RAM.

In short:  
 ✅ Use benchmarks upfront to pick smartly.  
 ✅ Use system metrics afterward to refine and optimize.

Both features give you clear, actionable data about how your workloads use compute resources — so you can choose the right machine, avoid waste, cut unnecessary costs, and get faster results without guesswork. In short: they help you optimize your spend and performance, every time you run a simulation.

```{banner_small}
:origin: scale_up_benchmarks_vs_system_metrics
```